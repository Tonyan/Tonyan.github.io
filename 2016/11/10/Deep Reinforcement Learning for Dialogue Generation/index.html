<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>论文速读《Deep Reinforcement Learning for Dialogue Generation》 | Tonya&#39;s Blog</title>
  
  
  
  <!--link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css"-->
  <link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css">
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="Shell">
    <aside class='SideBar'>
    <section class='avatar' style="background-image: url()">
        <div class='av-pic' style="background-image: url()">
        </div>
    </section>
    <section class='menu'>
        <div>Tonya&#39;s Blog</div>
        
        <ul>
          
            <a href="/" class="Btn">
              <li>Home</li>
            </a>  
          
            <a href="/archives/" class="Btn">
              <li>Archive</li>
            </a>  
          
        </ul>
    </section>
    <section class="media">
        
    </section>
</aside>

    <div class="container">
        <div data-pager-shell>
            <div>
  <article class='ContentView'>
    <header class='PageTitle'>
        <h1>论文速读《Deep Reinforcement Learning for Dialogue Generation》</h1>
    </header>

    <section>
      <h2 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a><a href="https://arxiv.org/abs/1606.01541" target="_blank" rel="noopener">原文链接</a></h2><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Jiwei Li</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>斯坦福</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Reinforcement Learning, seq2seq, text generation</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv.org(2016.06.25) &amp; EMNLP2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文提出利用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型</p>
<a id="more"></a>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>强化学习中的reward</p>
<p><img src="http://7xpodp.com1.z0.glb.clouddn.com/blog/20161123/231524231.png" alt=""></p>
<p>易被响应（Ease of answering），不容易出现对话僵局，其中 S 是无意义回答合集，s是某一时刻的响应</p>
<p><img src="http://7xpodp.com1.z0.glb.clouddn.com/blog/20161123/231624954.png" alt=""></p>
<p>信息流，若开辟新的话题，有利于对话的继续发展，隐层表示 hpi 和 hpi+1 的夹角余弦</p>
<p><img src="http://7xpodp.com1.z0.glb.clouddn.com/blog/20161123/231655514.png" alt=""></p>
<p>语义连贯性，减少与对话无关问题的影响，其中，pseq2seq(a|pi,qi) 是由上一轮状态得到响应的概率，后一项是由当前产生响应通过网络生成之前的 qi 的概率。</p>
<p>最终的reward是对三者加权求和，系数分别为：0.25、0.25、0.5<br><img src="http://7xpodp.com1.z0.glb.clouddn.com/blog/20161123/231723685.png" alt=""><br>对比试验：</p>
<ol>
<li>对话初始状态为一个SEQ2SEQ加attention的模型作为强化学习的初始状态</li>
<li>在1的基础上将最大互信息加入其中作为reward，对于一个给定的输入[pi,qi]，可以根据模型生成一个候选回答集合A。对于A中的每一个回答a,从预训练模型中得到的概率分布上可以计算出互信息的值 m(a,[pi,qi])。</li>
<li>将互信息训练过的模型作为初始模型，用策略梯度更新参数并加入课程学习策略，最终最多限定五轮对话</li>
</ol>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="http://7xpodp.com1.z0.glb.clouddn.com/DQN_related.png" alt="DQN相关"></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的思想其实非常符合写作的一种情况，就像贾岛推敲的故事，回想小时候刚学习写句子时，也不能一次写好，总会不断对一些词语进行修改。Google DeepMind的文章《DRAW：A Recurrent Neural Network For Image》也和本文异曲同工：画画也不是一次画好，也要不断的完善。不同之处在于本文率先引入DQN做文本生成。在机器学习各个分支下，强化学习和人类与环境的交互方式非常相似，在许多领域开始初露头角，期待看到更多将强化学习结合语言模型的应用。</p>


      

    </section>
    
      <section class='ArticleMeta'>
          <div>
            发布于&nbsp;
            <time datetime="2016-11-09T16:00:00.000Z" itemprop="datePublished">
              2016-11-10
            </time>
          </div>
          
            <div>
              tags: 
  <li class="meta-text">
  { <a href="/tags/NLP/">NLP</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/RL/">RL</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/chatbot/">chatbot</a> }
  </li>


            </div>
          
      </section>
    
    
</article>

  
</div>

            <footer>
    <div>© 2020 - Tonya Tsao </div>
    <div>
        <span>
            Powered by <a href="https://hexo.io">Hexo</a>
        </span>
        ,
        <span>
            Theme - <a href="https://github.com/nameoverflow/hexo-theme-icalm">Icalm</a>
        </span>
    </div>
</footer>

        </div>
    </div>
</div>
<script src="/js/pager/dist/singlepager.js"></script>
<script>
var sp = new Pager('data-pager-shell')

</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>