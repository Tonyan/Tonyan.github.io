{"total":13,"pageSize":10,"pageCount":2,"current":1,"data":[{"title":"会话管理","date":"2018-08-14T14:02:58.000Z","excerpt":"","slug":"会话管理"},{"title":"“会话管理”","date":"2018-08-14T14:02:35.000Z","excerpt":"","slug":"“会话管理”"},{"title":"numpy 安装学习","date":"2017-06-20T12:10:16.000Z","excerpt":"","slug":"numpy安装学习","tags":["机器学习"],"categories":["求知"]},{"title":"论文速读《Learning to Generate Reviews and Discovering Sentiment》","date":"2017-04-23T16:00:00.000Z","excerpt":"<h2 id=\"链接\"><a href=\"#链接\" class=\"headerlink\" title=\"链接\"></a><a href=\"https://arxiv.org/abs/1704.01444\" target=\"_blank\" rel=\"noopener\">链接</a></h2><p>##摘要<br>我们提出了一种byte-level的RNN language model。当给出足够的空间、训练数据、计算时间，通过该模型的表示包括disentangled features（不依赖特征？）和高水平的概念一致？<br>特别地，我们发现了一个单独的情感分析单元。这些表示学习了一个无监督的方式，并在斯坦福情感分析树图资料库SST的二元分类上取得了最好的结果。而且该模型数据有效？只用一部分的标注数据和在所有数据上取得的baseline相当。我们也证明了该情感单元对于模型的生成结果有直接影响。简单的修改他的值为积极或者消极生成的样例即为积极或者消极的情感。</p>\n<p>##简介和动机<br>表示学习在目前机器学习系统中扮演者关键的角色。表示将原始数据映射成更实用的形式，并且表示学习的选择对于任何应用都是至关重要的成分。更一般的说，有两个领域的研究强调如何学习有用表示的不同细节。<br>有标注的大规模语料高维度的监督学习训练是非常非常重要的</p>","slug":"Learning to Generate Reviews and Discovering Sentiment","tags":["sentiment","genetate"],"categories":["论文"]},{"title":"A Simple, Fast Diverse Decoding Algorithm for Neural Generation","date":"2016-12-20T12:10:16.000Z","excerpt":"","slug":"A Simple,Fast Diverse Decoding Algorithm for Neural Generation_Tonya","tags":["NLP","RL","chatbot"],"categories":["论文"]},{"title":"github page博客不同电脑管理","date":"2016-11-24T16:00:00.000Z","excerpt":"<p>目前本地已有github page所有文件，想直接建立两个分支分别存储源文件和生成好的博客<br>发现直接git新建分支不好用，此时在git中切换至存放博客的主目录执行,目的在于将当前文件初始化为git可管理文件<br><code>git init</code><br>由于刚刚初始化为git目录，现在识别不出master分支，会报错“fatal: Not a valid object name: ‘master’”<br>-解决该问题需要提交一次才可以，即<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add.</span><br><span class=\"line\">git commit -m &quot;commit&quot;</span><br></pre></td></tr></table></figure></p>","slug":"GithubPage不同电脑管理","tags":["技术"],"categories":["配置"]},{"title":"Hexo Latex公式支持","date":"2016-11-21T16:00:00.000Z","excerpt":"","slug":"折腾博客支持latex公式","tags":["技术"],"categories":["配置"]},{"title":"tensorflow-HPC配置方法","date":"2016-11-21T16:00:00.000Z","excerpt":"","slug":"tensorflow-HPC配置方法","tags":["技术"],"categories":["技术"]},{"title":"论文速读《Learning to compose words into sentences with reinforcement learning》","date":"2016-11-13T16:00:00.000Z","excerpt":"<h2 id=\"链接\"><a href=\"#链接\" class=\"headerlink\" title=\"链接\"></a><a href=\"https://openreview.net/forum?id=Skvgqgqxe\" target=\"_blank\" rel=\"noopener\">链接</a></h2><h2 id=\"作者\"><a href=\"#作者\" class=\"headerlink\" title=\"作者\"></a>作者</h2><p>Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling</p>\n<h2 id=\"单位\"><a href=\"#单位\" class=\"headerlink\" title=\"单位\"></a>单位</h2><p>google</p>\n<h2 id=\"关键词\"><a href=\"#关键词\" class=\"headerlink\" title=\"关键词\"></a>关键词</h2><p>Tree-LSTM, Reinforcement Learning</p>\n<h2 id=\"文章来源\"><a href=\"#文章来源\" class=\"headerlink\" title=\"文章来源\"></a>文章来源</h2><p>ICLR 2017</p>\n<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>使用强化学习来构建树结构的神经网络Tree-LSTM，学习自然语言的句子表示</p>","slug":"Learning to compose words into sentences with reinforcement learning_Tonya","tags":["RL"],"categories":["论文"]},{"title":"powerline配置","date":"2016-11-09T16:00:00.000Z","excerpt":"","slug":"powerline配置","tags":["配置"],"categories":["其他"]}]}