{"title":"论文速读《Learning to compose words into sentences with reinforcement learning》","date":"2016-11-13T16:00:00.000Z","excerpt":"<h2 id=\"链接\"><a href=\"#链接\" class=\"headerlink\" title=\"链接\"></a><a href=\"https://openreview.net/forum?id=Skvgqgqxe\" target=\"_blank\" rel=\"noopener\">链接</a></h2><h2 id=\"作者\"><a href=\"#作者\" class=\"headerlink\" title=\"作者\"></a>作者</h2><p>Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling</p>\n<h2 id=\"单位\"><a href=\"#单位\" class=\"headerlink\" title=\"单位\"></a>单位</h2><p>google</p>\n<h2 id=\"关键词\"><a href=\"#关键词\" class=\"headerlink\" title=\"关键词\"></a>关键词</h2><p>Tree-LSTM, Reinforcement Learning</p>\n<h2 id=\"文章来源\"><a href=\"#文章来源\" class=\"headerlink\" title=\"文章来源\"></a>文章来源</h2><p>ICLR 2017</p>\n<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>使用强化学习来构建树结构的神经网络Tree-LSTM，学习自然语言的句子表示</p>","slug":"Learning to compose words into sentences with reinforcement learning_Tonya","comments":true,"tags":["RL"],"categories":["论文"],"updated":"2018-07-03T17:13:56.000Z","content":"<h2 id=\"链接\"><a href=\"#链接\" class=\"headerlink\" title=\"链接\"></a><a href=\"https://openreview.net/forum?id=Skvgqgqxe\" target=\"_blank\" rel=\"noopener\">链接</a></h2><h2 id=\"作者\"><a href=\"#作者\" class=\"headerlink\" title=\"作者\"></a>作者</h2><p>Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling</p>\n<h2 id=\"单位\"><a href=\"#单位\" class=\"headerlink\" title=\"单位\"></a>单位</h2><p>google</p>\n<h2 id=\"关键词\"><a href=\"#关键词\" class=\"headerlink\" title=\"关键词\"></a>关键词</h2><p>Tree-LSTM, Reinforcement Learning</p>\n<h2 id=\"文章来源\"><a href=\"#文章来源\" class=\"headerlink\" title=\"文章来源\"></a>文章来源</h2><p>ICLR 2017</p>\n<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>使用强化学习来构建树结构的神经网络Tree-LSTM，学习自然语言的句子表示</p>\n<a id=\"more\"></a>\n<h2 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h2><p>模型分为两部分：Tree-LSTM和强化学习模型<br>应用Tree-LSTM(可以通过LSTM的忘记门机制，跳过整棵对结果影响不大的子树)，并结合{SHIFT，REDUCE}操作，SHIFT操作对应将一个节点压入栈，REDUCE对应将两个元素组合，从而建立树结构</p>\n<p>强化学习用来寻找最佳的节点组合情况，RL模型中的状态s即当前构建的树结构，a为{SHIFT，REDUCE}操作，reward对应不同downstream<br> task(例：若是用该句子表示进行分类任务，则r对应从策略网络中采样得到句子表示的分类准确性的概率)</p>\n<h2 id=\"资源\"><a href=\"#资源\" class=\"headerlink\" title=\"资源\"></a>资源</h2><p>作者将该工作进行了四组实验，情感分类，语义相关性判断，自然语言推理，句子生成<br>分别应用Stanford Sentiment Treebank，Sentences Involving Compositional Knowledge corpus，Stanford Natural Language Inference corpus，IMDB movie review corpus</p>\n<h2 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h2><p>与Socher等人之前提出的Recursive NN,MV-RNN,RNTN，Tree-LSTM等工作一脉相承，本文又加入了RL方式构建树形结构</p>\n<h2 id=\"简评\"><a href=\"#简评\" class=\"headerlink\" title=\"简评\"></a>简评</h2><p>将强化学习引入句子表示学习之中，学习构建树的不同方式，从左向右，从右向左，双向，有监督、半监督、预先无结构等方式去构建树结构，但是训练时间较长，在几个任务上效果提升不是特别明显</p>\n","prev":{"title":"tensorflow-HPC配置方法","slug":"tensorflow-HPC配置方法"},"next":{"title":"powerline配置","slug":"powerline配置"},"link":"http://yoursite.com/post/Learning to compose words into sentences with reinforcement learning_Tonya","toc":[{"title":"作者","id":"作者","index":"1"},{"title":"单位","id":"单位","index":"2"},{"title":"关键词","id":"关键词","index":"3"},{"title":"文章来源","id":"文章来源","index":"4"},{"title":"问题","id":"问题","index":"5"},{"title":"模型","id":"模型","index":"6"},{"title":"资源","id":"资源","index":"7"},{"title":"相关工作","id":"相关工作","index":"8"},{"title":"简评","id":"简评","index":"9"}]}